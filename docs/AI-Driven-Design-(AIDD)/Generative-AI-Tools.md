# Introduction

There are a lot of different [generative AI](https://generativeai.net/) tools available online to use.
The most known of which use _text to image_ models, eg. DALL-E 2, or _large language models (LLM)_, eg. ChatGPT, but you als have _text to audio_, _text to music_, _text to video_, _real to stylized video_ and _image to 3D models_.
Most of these however are closed source and require a paid subscription to be able to use them. Although they often offer free credits that can be used for experimentation and finding the right tool for the job at hand. These often also return after a certain period of time.
Other models are open source and free to use on your own systems or through platforms like Google Colab to offload the processing power needed for the model to run. In the nature of open source projects, these also sprout all kinds of variations and models trained for specific purposes or styles.

_Note: all details are as of writing in Q1 2023._

---

# Text to Image

Text to image models generate an image from a given prompt.
A prompt can be a full sentence, random words or a mix of both separated by commas, depending on the specific model.
Often there are also more advanced options like:
- Negative prompt: things you don't want in the image.
- Weights: with which you can give a heavier weight to words, meaning making some words more important than others.
- Seed: number to control or limit the randomness of the image generation. This is often a random number, but by setting it to a fixed number you can more easily monitor the influences of changing a prompt.

## [DALL-E 2](https://openai.com/product/dall-e-2)

- **Model:** text to image and image expansion
- **License:** closed source
- **Usage:** [website](https://labs.openai.com/) and API
- **Pricing website:** 4 images per credit, 50 free credits, 15 free every month, $15 for 115.
- **Pricing API:** $0.02 per 1024×1024 image, $0.018 per 512×512 image, $0.016 per 256×256 image. Enterprise team subscriptions possible.

DALL-E 2 is probably one of the easiest and best tools for non experts.
It's a closed source _text to image_ model by OpenAI with which you can generate photorealistic and artistic images. It also has some extra feature like expanding existing images or photos beyond their original frame.
[A short explanation is available on their website](https://openai.com/product/dall-e-2).
It works through a [webpage](https://labs.openai.com/) were you can write a prompt or upload an image, as well as through an API.

## [Midjourney](https://www.midjourney.com/)

- **Model:** text to image and photo to image
- **License:** closed source
- **Usage:** Discord channel
- **Pricing:** Free trial of 25 min. GPU time, Basic at $10/month for 200 min/month, Standard at $30/month for 15h/month, Corporate at $600/year for 120h/year.

Midjourney is a model created by a researchgroup which generates more artistic images, often concept art style looking. It's still in beta and works through a Discord channel which you can join by clicking the _Join the Beta_ button on [their website](https://www.midjourney.com/).
The pricing is counted in GPU time the AI model spends generating your images. You get a free trial in the beginning of 25 minutes GPU time which regenerates every month.

To generate images join the Discord channel, go to a _newbies_ thread, and write `/imagine`. A pop-up will show up for this command `/imagine prompt:`. Select it and write your prompt. This is a shared thread, so all images being generated by other users also show up. You can follow the generation of your image in the command you posted. When it's finished a new message is created with the result mentioning your username.

## [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)

- **Model:** text to image and photo to image
- **License:** open source
- **Usage:** website, local, Google Colab Notebook, etc.
- **Pricing:** Free (virtual machine costs may apply.)

[Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release) is an open source projects. As most popular open source projects it has sprouted a lot of different versions trained for specific tasks and styles. Here are the easiest and most useful ways to use it:

- [Stable Diffusion Playground web interface](https://stablediffusionweb.com/#demo): this is an easy webinterface similair to DALL-E to demonstrate the model. Just write the prompt and press _Generate image_. There is also a [prompt database](https://stablediffusionweb.com/prompts) available to get ideas of possible prompts.

- [Hugging Face Demo web interface](https://huggingface.co/spaces/stabilityai/stable-diffusion): Hugging Face is an open source AI organization. They also provide a free web interface to demo Stable Diffusion similar to the Stable Diffusion Playground.

- [Google Colab Notebooks](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb): if you just google it you can find a lot of different Google Colab Notebooks created by users to use. This is one example using a specific model, but a lot of other models are available to use as well. You can also couple your Google Drive to a Notebook to auto save the resulting images to it. This approach is for a bit more advanced users, but provides the possibility to change and add code in Python.

- [Dream Studio](https://beta.dreamstudio.ai/dream): is another web interface that features faster generation and makes some parameters available as sliders that are available in code when you use a Notebook.

- [Running locally from GitHub repo](https://github.com/CompVis/stable-diffusion): another possibility is cloning the Stable Diffusion repository on GitHub and running it locally on your own system. How to do this is documented in the README of the repo.

- [Blender Plug-in](https://blendermarket.com/products/ai-render): there is also a plug-in available to use Stable Diffusion within Blender. It's still only 2D image generation, but can be used to for example generate textures and 2D animations. The generation is not run locally, but through an API for which you'll need a key.

## [Photosonic](https://app.writesonic.com/photosonic)

- **Model:** text to image
- **License:** closed source
- **Usage:** website
- **Pricing:** Free Trial 2500 words/month, Long-form $13-1749/month for 19-5750k words/month. 1 image generation gives you 2 images and costs 100 words.

Photosonic is a tool by Writesonic that offer a range of AI tools. It uses a web interface similar to DALL-E 2. It uses words as it's credits because it also has a chat AI called Chatsonic where this system is easier to understand.

---

# Large Language Models

## [ChatGPT](https://openai.com/blog/chatgpt)

- **License:** closed source
- **Usage:** [website](https://chat.openai.com/chat)
- **Pricing:** Free Trial 2500 words/month, Long-form $13-1749/month for 19-5750k words/month.

A chat AI by OpenAI.

## [Chatsonic](https://app.writesonic.com/template/2a90e7da-1cec-44d3-bfd0-174d0c265e47/chatsonic/d16f254f-134c-4fbf-929f-76f36fa09179)

- **License:** closed source
- **Usage:** website, Chrome plug-in
- **Pricing:** Free Plan available when demand is low. Plus plan for $20/month giving access even when demand is high, faster response speed and priority access to new features.

A chat AI by Writesonic.